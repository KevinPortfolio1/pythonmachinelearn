--------------
監督
--------------
回歸
 預測「連續數值」的問題，例如房價、氣溫、銷售量等
 找出輸入特徵與目標變數之間的「數學關係」，例如線性方程式：y = wx + b
 LinearRegression, Ridge, Lasso, SVR, DecisionTreeRegressor 等
決策樹
 以「條件判斷」方式建立分支的樹狀模型。每個節點代表一個特徵的條件判斷。
 利用資訊增益（Information Gain）或基尼係數（Gini impurity）選擇最佳分裂特徵。
 DecisionTreeClassifier, DecisionTreeRegressor
隨機森林
 由多棵「決策樹」組成的集成模型（ensemble method）。透過投票或平均來做預測。
 使用「Bagging（自助採樣）」建立多棵樹，減少過擬合、提升穩定性。
 RandomForestClassifier, RandomForestRegressor
svm
 找出一條「能最大區分兩類」的超平面（Hyperplane）。
 最大化兩類資料與分隔邊界的間隔（margin）；可以使用 kernel trick 做非線性分類。
 SVC（分類），SVR（回歸）
神經網路
	模仿人腦神經元架構的模型，由「多層感知器（MLP）」組成。適合處理非線性關係。
	由多層神經元組成，每層經過線性運算與非線性激活函數後再輸出至下一層。
	MLPClassifier, MLPRegressor

--------------
非監督
--------------
k-means
	把資料依距離分成 K 個群組。每個資料點分到最近的「中心點」。
	隨機選 K 個中心點 → 重複分群與更新中心直到收斂。用歐幾里得距離。
	✅ KMeans(n_clusters=K)
dbscan
	根據資料「密度」進行分群，可辨識不規則形狀的群體，並標出異常值（雜訊）。
	以距離半徑 (eps) 和最小點數 (min_samples) 定義密度區域。
	✅ DBSCAN(eps=..., min_samples=...)
pca
	把高維資料轉換為低維空間，保留最多變異量。常用於資料降維與視覺化。
	找出特徵間的線性組合，使變異量（資訊）最大化，並以此排序主成分。
	✅ PCA(n_components=...)
autoencoder
	一種神經網路，將輸入資料壓縮到低維表示，再嘗試還原輸入。用於非線性降維、特徵學習。
	由 Encoder（壓縮）與 Decoder（還原）組成，訓練目標是最小化重建誤差。
	TensorFlow / Keras → Model(inputs, outputs)


📊 Scikit-learn 方法總覽表格

| 方法                               | 類別  |	 Scikit-learn 支援                          	| 官方文件 / 範例                                                                     |
| -------------------------------- | --- | ---------------------------------------- | ----------------------------------------------------------------------------- |
| **回歸 (Regression)**              | 	監督式 | 	✅ 支援 (如 `LinearRegression`)              | [文件](https://scikit-learn.org/stable/modules/linear_model.html)               |
| **決策樹 (Decision Tree)**          | 監督式 | 	✅ `DecisionTreeClassifier` / `Regressor` 	| [範例](https://scikit-learn.org/stable/modules/tree.html)                       |
| **隨機森林 (Random Forest)**         | 監督式 | 	✅ `RandomForestClassifier` / `Regressor` 	| [文件](https://scikit-learn.org/stable/modules/ensemble.html#forest)            |
| **SVM (Support Vector Machine)** | 	監督式 | 		✅ `SVC`, `SVR`                           | [文件](https://scikit-learn.org/stable/modules/svm.html)                        |
| **神經網路 (Neural Network)**        | 監督式 | 	✅ `MLPClassifier`, `MLPRegressor`        		| [文件](https://scikit-learn.org/stable/modules/neural_networks_supervised.html) |


| 方法              | 類別   	| Scikit-learn 支援              | 官方文件 / 範例                                                             |
| --------------- 	| ---- | ---------------------------- 			| --------------------------------------------------------------------- |
| **K-means**     	| 非監督式 | ✅ `KMeans`                   		| [文件](https://scikit-learn.org/stable/modules/clustering.html#k-means) |
| **DBSCAN**      	| 非監督式 | ✅ `DBSCAN`                   			| [文件](https://scikit-learn.org/stable/modules/clustering.html#dbscan)  |
| **PCA**         	| 非監督式 | ✅ `PCA`                      			| [文件](https://scikit-learn.org/stable/modules/decomposition.html#pca)  |
| **Autoencoder** 	| 非監督式 | ❌ 不支援（需用 TensorFlow / Keras） | ❌ 無內建，需要用其他框架    


| 工具                       | 建議用途               		| 難度       | 備註                   |
| ------------------------ | ------------------ | -------- | -------------------- |
| **scikit-learn**         | 初學者首選，涵蓋所有基本模型     | ⭐️ 易     | ✅ 文檔清楚、社群多           |
| **pandas / numpy**       | 資料前處理與分析           	| ⭐️ 易     	| ✅ 搭配 scikit-learn 使用 |
| **matplotlib / seaborn** | 資料視覺化              		| ⭐️ 易     	| ✅ 重要但容易學             |
| **TensorFlow / Keras**   | 深度學習 / Autoencoder 		| ⭐️⭐️⭐️ 難 	| ❌ 初期不建議使用，先學基礎概念     |


✅ 結論：建議開始順序

建議你先練這三個：

	LinearRegression：理解資料關係與評估指標（MSE）

	DecisionTreeClassifier：掌握分類與模型視覺化

	KMeans + PCA：了解非監督學習與資料視覺化

然後再進階到：

	RandomForest

	SVM

	Neural Network (MLP)

	DBSCAN（了解密度分群）
                                                     |
