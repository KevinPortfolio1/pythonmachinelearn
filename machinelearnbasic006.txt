Scikit 

1.Linear Models

	ç·šæ€§æ¨¡å‹æ˜¯ä¸€é¡å‡è¨­è¼¸å‡ºè®Šæ•¸ï¼ˆyï¼‰èˆ‡è¼¸å…¥è®Šæ•¸ï¼ˆXï¼‰ä¹‹é–“å‘ˆç·šæ€§é—œä¿‚çš„æ¨¡å‹ã€‚
	
	å¸¸è¦‹çš„ç·šæ€§æ¨¡å‹åŒ…æ‹¬ï¼š

		ç·šæ€§å›æ­¸ï¼ˆLinear Regressionï¼‰

		é‚è¼¯å›æ­¸ï¼ˆLogistic Regressionï¼‰

		Ridge Regression / Lasso Regression

		SGDClassifier / SGDRegressor
		
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_regression
import matplotlib.pyplot as plt

# ç”¢ç”Ÿæ¨¡æ“¬è³‡æ–™
X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)

# åˆ†å‰²è³‡æ–™é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# å»ºç«‹æ¨¡å‹
model = LinearRegression()
model.fit(X_train, y_train)

# é æ¸¬
y_pred = model.predict(X_test)

# ç¹ªåœ–
plt.scatter(X_test, y_test, color='blue', label='Actual')
plt.plot(X_test, y_pred, color='red', label='Predicted')
plt.legend()
plt.title("Linear Regression Example")
plt.show()

# å°å‡ºä¿‚æ•¸èˆ‡æˆªè·
print("ä¿‚æ•¸ (slope):", model.coef_)
print("æˆªè· (intercept):", model.intercept_)


âœ… æ¨™æº–æµç¨‹ï¼š

è³‡æ–™æº–å‚™ï¼ˆData Preparationï¼‰

å»ºç«‹æ¨¡å‹ç‰©ä»¶ï¼ˆInstantiate modelï¼‰

è¨“ç·´æ¨¡å‹ï¼ˆfitï¼‰

æ¨¡å‹é æ¸¬ï¼ˆpredictï¼‰

æ¨¡å‹è©•ä¼°ï¼ˆscore, metricsï¼‰


2.Gaussian mixture models

	é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGaussian Mixture Model, GMMï¼‰æ˜¯ä¸€ç¨®æ©Ÿç‡å¼èšé¡æ¨¡å‹ï¼Œå‡è¨­è³‡æ–™ä¾†è‡ªæ•¸å€‹ä¸åŒçš„é«˜æ–¯åˆ†å¸ƒï¼ˆæ­£æ…‹åˆ†å¸ƒï¼‰çš„çµ„åˆã€‚
	èˆ‡ K-Means ç›¸æ¯”ï¼ŒGMM æ›´éˆæ´»ï¼Œèƒ½å¤ å»ºæ¨¡æ©¢åœ“å½¢çš„è³‡æ–™åˆ†å¸ƒã€‚

	å±¬æ–¼éç›£ç£å­¸ç¿’ï¼ˆunsupervised learningï¼‰

	å¯ä»¥ä½¿ç”¨ EM æ¼”ç®—æ³•ä¾†ä¼°è¨ˆåƒæ•¸
	
from sklearn.mixture import GaussianMixture
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# ç”¢ç”Ÿæ¨¡æ“¬è³‡æ–™ï¼ˆ3å€‹ç¾¤ï¼‰
X, y_true = make_blobs(n_samples=300, centers=3, cluster_std=0.60, random_state=0)

# å»ºç«‹ GMM æ¨¡å‹
gmm = GaussianMixture(n_components=3, random_state=0)
gmm.fit(X)

# é æ¸¬ cluster label
labels = gmm.predict(X)

# ç¹ªåœ–
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.title("Gaussian Mixture Model Clustering")
plt.show()
	
âœ… æ¨™æº–æµç¨‹ï¼š

è³‡æ–™æº–å‚™ï¼ˆData Preparationï¼‰

å»ºç«‹æ¨¡å‹ç‰©ä»¶ï¼ˆGaussianMixtureï¼‰

è¨“ç·´æ¨¡å‹ï¼ˆfitï¼‰

æ¨è«–åˆ†ç¾¤çµæœï¼ˆpredictï¼‰

ï¼ˆå¯é¸ï¼‰å–å¾—æ©Ÿç‡ / å„æˆåˆ†åƒæ•¸ï¼ˆpredict_proba, means_, covariances_ï¼‰


-------------------------------------------------------------------------------------
ğŸ” é€šç”¨ Scikit-learn å·¥ä½œæµç¨‹ç¸½çµï¼š
æ­¥é©Ÿ	èªªæ˜				æ–¹æ³•åç¨±
1		è¼‰å…¥æˆ–å»ºç«‹è³‡æ–™		X, y
2		å»ºç«‹æ¨¡å‹			model = ...()
3		è¨“ç·´æ¨¡å‹			model.fit(X, y)
4		é æ¸¬æˆ–åˆ†ç¾¤çµæœ		model.predict()
5		è©•ä¼°æˆ–æŸ¥çœ‹åƒæ•¸		score(), metrics, model.coef_, means_ ç­‰